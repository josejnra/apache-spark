{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4807307d-c64e-451a-b104-87ec5d06df95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.num_executors = 4\n",
    "launcher.executor_cores = 2\n",
    "launcher.driver_memory = \"4g\"\n",
    "launcher.conf.set(\"spark.sql.catalogImplementation\", \"hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1e9e90-66ad-497f-8efb-19657e8670b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4364fab6\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40582db7-3ca5-4bcd-82a5-3f1cd305d09d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: String = 3.3.2\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427c23e-95b5-4edb-a15c-54c97770278b",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1c0516-da5f-4a44-a1de-1fab3ca5cf98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number| word|\n",
      "+------+-----+\n",
      "|     8|  bat|\n",
      "|    64|mouse|\n",
      "|   -27|horse|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val someDF = Seq(\n",
    "    (8, \"bat\"),\n",
    "    (64, \"mouse\"),\n",
    "    (-27, \"horse\"),\n",
    ").toDF(\"number\", \"word\")\n",
    "\n",
    "someDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d044403d-4892-440b-be2c-1a93ddae521c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number| word|\n",
      "+------+-----+\n",
      "|     8|  bat|\n",
      "|    64|mouse|\n",
      "|   -27|horse|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.Row\n",
       "someData: Seq[org.apache.spark.sql.Row] = List([8,bat], [64,mouse], [-27,horse])\n",
       "someSchema: List[org.apache.spark.sql.types.StructField] = List(StructField(number,IntegerType,true), StructField(word,StringType,true))\n",
       "someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")\n",
    "\n",
    "someDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3b33ca-341e-47c1-baed-6861543f8730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|number| word|boolean|\n",
      "+------+-----+-------+\n",
      "|     8|  bat|  false|\n",
      "|    64|mouse|   true|\n",
      "|   -27|horse|   true|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "someRDD: org.apache.spark.rdd.RDD[(Int, String, Boolean)] = ParallelCollectionRDD[13] at parallelize at <console>:30\n",
       "someDF: org.apache.spark.sql.DataFrame = [number: int, word: string ... 1 more field]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val someRDD = sc.parallelize(Seq(\n",
    "  (8, \"bat\", false),\n",
    "  (64, \"mouse\", true),\n",
    "  (-27, \"horse\", true)\n",
    "))\n",
    "\n",
    "val someDF = someRDD.toDF(\"number\", \"word\", \"boolean\")\n",
    "someDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59a86d-53b9-4f80-9682-83dd14dca23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
