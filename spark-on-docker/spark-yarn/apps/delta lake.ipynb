{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4cba42-4236-41d0-b79b-a1c3d86ed1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 22:00:53,669 WARN util.Utils: Your hostname, localhost resolves to a loopback address: 127.0.0.1; using 192.168.32.2 instead (on interface eth0)\n",
      "2022-02-20 22:00:53,669 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.2.1-bin-without-hadoop/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.amazonaws#aws-java-sdk-s3 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-daa305bd-4090-4164-9650-232de12841e8;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.2.1-bin-without-hadoop/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.161 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.161 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.161 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.12.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.12.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.12.6 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.6 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.161 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound io.delta#delta-core_2.12;1.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      ":: resolution report :: resolve 321ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.161 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.161 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.161 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.161 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.12.6 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.12.6 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.6 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.6 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-core_2.12;1.1.0 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   22  |   0   |   0   |   2   ||   20  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-daa305bd-4090-4164-9650-232de12841e8\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 19 already retrieved (187813kB/265ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-02-20 22:00:56,069 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2022-02-20 22:01:01,248 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.1.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/io.delta_delta-core_2.12-1.1.0.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/joda-time_joda-time-2.8.1.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,249 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,250 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,250 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar added multiple times to distributed cache.\n",
      "2022-02-20 22:01:01,250 WARN yarn.Client: Same path resource file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar added multiple times to distributed cache.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Delta Lake</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe304143cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "config = SparkConf() \\\n",
    "                    .setAppName('Delta Lake') \\\n",
    "                    .setAll([('spark.executor.memory', '4G'),\n",
    "                            ('spark.driver.memory', '2G'),\n",
    "                            ('spark.driver.maxResultSize', '1G')]) \\\n",
    "                    .set(\"spark.jars.packages\", \"com.amazonaws:aws-java-sdk-s3:1.12.161,org.apache.hadoop:hadoop-aws:3.3.1,io.delta:delta-core_2.12:1.1.0\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.name\", \"directory\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.staging.conflict-mode\", \"replace\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.staging.tmp.path\", \"/tmp/staging\") \\\n",
    "                    .set(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                    .set(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "sc = SparkContext(conf=config)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# spark = SparkSession.builder.config(conf=config)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9857b07a-9017-4436-980e-f497aa2808c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "from pyspark.sql.functions import lit\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7d12971-9370-43a3-b7d5-e99a09e72125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   1  Alice  2022-01-01\n",
       "1   2  Braga  2022-02-02\n",
       "2   3  Steve  2022-03-03"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  [{'id': 1, 'name': 'Alice', 'updated_at': datetime(2022, 1, 1)},\n",
    "         {'id': 2, 'name': 'Braga', 'updated_at': datetime(2022, 2, 2)},\n",
    "         {'id': 3, 'name': 'Steve', 'updated_at': datetime(2022, 3, 3)}]\n",
    "\n",
    "schema = StructType([StructField('id', IntegerType(), nullable=True),\n",
    "                     StructField('name', StringType(), nullable=True),\n",
    "                     StructField('updated_at', DateType(), nullable=True)])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4acc7-980e-480d-970a-d745e8928ca3",
   "metadata": {},
   "source": [
    "## Create Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4feef-a3c2-4ae4-aa1d-defc6759f067",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e926c632-bc4b-498a-828b-d708ba5f879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create or replace partitioned table with path using DataFrame's schema and write/overwrite data to it\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"userMetadata\", \"some comments\") \\\n",
    "  .save(\"/delta-lake/users\")\n",
    "\n",
    "# Create table in the metastore using DataFrame's schema and write data to it\n",
    "# df.write.format(\"delta\") \\\n",
    "#   .mode(\"overwrite\") \\\n",
    "#   .option(\"mergeSchema\", \"true\") \\\n",
    "#   .saveAsTable(\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732cae1-0263-4085-a76a-c29e5ca67bb4",
   "metadata": {},
   "source": [
    "### Minio (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fe19d-24ab-4b8e-95b7-61bc67dbb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .save(\"s3a://my-bucket//delta-lake/users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7523a0-fffd-4330-8d92-efa7775e9c47",
   "metadata": {},
   "source": [
    "### Create table without data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6be46f-e6a8-45ef-884a-a3eb6ad12e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_table = DeltaTable.createOrReplace(spark) \\\n",
    "  .addColumn(\"id\", \"INT\") \\\n",
    "  .addColumn(\"firstName\", \"STRING\") \\\n",
    "  .addColumn(\"middleName\", \"STRING\") \\\n",
    "  .addColumn(\"lastName\", \"STRING\", comment = \"surname\") \\\n",
    "  .addColumn(\"gender\", \"STRING\") \\\n",
    "  .addColumn(\"birthDate\", \"TIMESTAMP\") \\\n",
    "  .addColumn(\"ssn\", \"STRING\") \\\n",
    "  .addColumn(\"salary\", \"INT\") \\\n",
    "  .property(\"description\", \"table with people data\") \\\n",
    "  .location(\"/delta-lake/my-table\") \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc711eee-64f6-4350-a6d6-1226c63e6e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:04:09.548</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName                operation  \\\n",
       "0        0 2022-02-20 22:04:09.548   None     None  CREATE OR REPLACE TABLE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "\n",
       "   readVersion     isolationLevel  isBlindAppend operationMetrics  \\\n",
       "0          NaN  SnapshotIsolation           True               {}   \n",
       "\n",
       "  userMetadata                           engineInfo  \n",
       "0         None  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as delta format\n",
    "my_table = DeltaTable.forPath(spark, \"/delta-lake/my-table\")\n",
    "my_table.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e072f4c8-5eec-40a9-931a-9acc0163488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>ssn</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, firstName, middleName, lastName, gender, birthDate, ssn, salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970952c-57ff-4437-bfa3-bf5299ead1f3",
   "metadata": {},
   "source": [
    "## Read Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4632ca-ceed-4d81-b543-872334e4f5f9",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "666726ce-9a41-4283-aac7-3aadb4ebe785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as delta format\n",
    "spark.read.format(\"delta\") \\\n",
    "     .load(\"/delta-lake/users\") \\\n",
    "     .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248a9123-9c17-445f-9576-6b81e198822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM delta.`/delta-lake/users` -- query table by path\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ab76a7-7e28-4b53-9925-ca03c9fcfc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03\n",
       "4   1   Alice  2022-01-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as parquet format\n",
    "spark.read.format(\"parquet\") \\\n",
    "     .load(\"/delta-lake/users\") \\\n",
    "     .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c55f6-5592-4e94-8d06-2d1bd2c13598",
   "metadata": {},
   "source": [
    "### Minio (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43a136-14e2-49b9-8264-8108cffb4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\") \\\n",
    "     .load(\"s3a://my-bucket/delta-lake/users\") \\\n",
    "     .toPandas()\n",
    "\n",
    "# spark.read.format(\"parquet\") \\\n",
    "#      .load(\"s3a://my-bucket//delta-lake/users\") \\\n",
    "#      .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a04777-5946-4af7-a1cd-728e4bd736a4",
   "metadata": {},
   "source": [
    "## Describe tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c458d1e-d49b-403f-88dc-ec039a3b3585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-20 22:11:18.529</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '2', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:03:47.787</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '3', 'numOutputBytes': '1880...</td>\n",
       "      <td>some comments</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName operation  \\\n",
       "0        1 2022-02-20 22:11:18.529   None     None     MERGE   \n",
       "1        0 2022-02-20 22:03:47.787   None     None     WRITE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "1         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          0.0   Serializable          False   \n",
       "1          NaN   Serializable          False   \n",
       "\n",
       "                                    operationMetrics   userMetadata  \\\n",
       "0  {'numOutputRows': '2', 'numTargetRowsInserted'...           None   \n",
       "1  {'numOutputRows': '3', 'numOutputBytes': '1880...  some comments   \n",
       "\n",
       "                            engineInfo  \n",
       "0  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "1  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table = DeltaTable.forPath(spark, \"/delta-lake/users\")\n",
    "users_table.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d62bbc-f2bb-4cb9-abf8-ddec32098130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>partitionColumns</th>\n",
       "      <th>numFiles</th>\n",
       "      <th>sizeInBytes</th>\n",
       "      <th>properties</th>\n",
       "      <th>minReaderVersion</th>\n",
       "      <th>minWriterVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>0b8f1ca3-c7bf-4740-89ea-678beefb4baf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>hdfs://localhost:9000/delta-lake/users</td>\n",
       "      <td>2022-02-20 22:03:45.023</td>\n",
       "      <td>2022-02-20 22:03:47.787</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1880</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  format                                    id  name description  \\\n",
       "0  delta  0b8f1ca3-c7bf-4740-89ea-678beefb4baf  None        None   \n",
       "\n",
       "                                 location               createdAt  \\\n",
       "0  hdfs://localhost:9000/delta-lake/users 2022-02-20 22:03:45.023   \n",
       "\n",
       "             lastModified partitionColumns  numFiles  sizeInBytes properties  \\\n",
       "0 2022-02-20 22:03:47.787               []         2         1880         {}   \n",
       "\n",
       "   minReaderVersion  minWriterVersion  \n",
       "0                 1                 2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    DESCRIBE DETAIL delta.`/delta-lake/users` -- query table by path\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eaf45c1-e02f-450d-a184-312c7b845463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>partitionColumns</th>\n",
       "      <th>numFiles</th>\n",
       "      <th>sizeInBytes</th>\n",
       "      <th>properties</th>\n",
       "      <th>minReaderVersion</th>\n",
       "      <th>minWriterVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>931b0889-4c4f-4f45-98aa-d64052cb5fbd</td>\n",
       "      <td>default.users</td>\n",
       "      <td>None</td>\n",
       "      <td>file:/opt/apps/spark-warehouse/users</td>\n",
       "      <td>2022-02-20 18:40:31.589</td>\n",
       "      <td>2022-02-20 22:03:55.757</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1880</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  format                                    id           name description  \\\n",
       "0  delta  931b0889-4c4f-4f45-98aa-d64052cb5fbd  default.users        None   \n",
       "\n",
       "                               location               createdAt  \\\n",
       "0  file:/opt/apps/spark-warehouse/users 2022-02-20 18:40:31.589   \n",
       "\n",
       "             lastModified partitionColumns  numFiles  sizeInBytes properties  \\\n",
       "0 2022-02-20 22:03:55.757               []         2         1880         {}   \n",
       "\n",
       "   minReaderVersion  minWriterVersion  \n",
       "0                 1                 2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only if delta table saved as table\n",
    "spark.sql(\"\"\"\n",
    "    DESCRIBE DETAIL users\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abb906c-113f-4381-9dee-81bf8db7325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only if delta table saved as table\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM users\n",
    "    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fef1c17-cf1f-43d2-91d3-1e039f4965fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>users</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace tableName  isTemporary\n",
       "0   default     users        False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tables in metastore\n",
    "spark.sql(\"\"\"\n",
    "    SHOW tables\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305931e-7ed5-4718-a8e9-ba7e33c8d546",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upsert (Merge) new Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "64cf4061-8e7f-47a6-a660-a3df43a3cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = DeltaTable.forPath(spark, \"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa5f0de7-2a33-4252-9546-bcf430b65eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [{'id': 1, 'name': 'Alice', 'updated_at': datetime(2022, 1, 2)},\n",
    "            {'id': 4, 'name': 'Carell', 'updated_at': datetime(2022, 4, 4)}]\n",
    "\n",
    "new_data_df = spark.createDataFrame(new_data, schema=schema)\n",
    "new_data_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9c6ae-dde1-4496-92a1-37035b5f19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=new_data_df.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdate(set={\n",
    "                                    \"updated_at\": \"new_data.updated_at\"\n",
    "                              }) \\\n",
    "           .whenNotMatchedInsert(values={\n",
    "                                            \"id\": \"new_data.id\",\n",
    "                                            \"name\": \"new_data.name\",\n",
    "                                            \"updated_at\": \"new_data.updated_at\"\n",
    "                                }) \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4fdc734b-fdf6-4bf3-88bf-187b82ca1823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=new_data_df.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdateAll() \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643ffa3-eb70-4d1b-aa40-9f5cce722bfc",
   "metadata": {},
   "source": [
    "### Upsert with Missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad4dcdf9-4c82-4121-bafc-8d7f4b4efc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  name updated_at\n",
       "0   5  Joao       None"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_missing_fields = [{\"id\": 5, 'name': 'Joao'}]\n",
    "\n",
    "data_missing_fields = spark.createDataFrame(data_missing_fields, schema=schema)\n",
    "data_missing_fields.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5db6fe9d-b5d2-481a-94da-c39d3befe469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03\n",
       "4   5    Joao        None"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=data_missing_fields.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdateAll() \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f9daf-02e6-47e2-9786-12e0d0bbd34f",
   "metadata": {},
   "source": [
    "## Update Schema adding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2d5f5af-9f60-4d8f-b884-a99bc23ad1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as delta format\n",
    "update_schema = spark.read.format(\"delta\").load(\"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d3ae7ed-ee12-4b0b-81fa-fb867365391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- updated_at: date (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add column\n",
    "update_schema = update_schema.withColumn(\"age\", lit(None).cast(StringType()))\n",
    "update_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8578df30-87c7-4ae8-94b6-c2777d7d945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at   age\n",
       "0   1   Alice  2022-01-02  None\n",
       "1   4  Carell  2022-04-04  None\n",
       "2   2   Braga  2022-02-02  None\n",
       "3   3   Steve  2022-03-03  None\n",
       "4   5    Joao        None  None"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_schema.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58afc83e-32f3-4ebc-af7f-13af7bb4ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Merge Schema, another option is overwriteSchema\n",
    "update_schema.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"userMetadata\", \"add age column\") \\\n",
    "  .save(\"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74698b00-c46f-4ebc-81b0-5a138c0f4bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-02-20 22:56:30.573</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '7', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-20 22:50:27.894</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '10', 'numOutputBytes': '243...</td>\n",
       "      <td>add age column</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-20 22:48:36.639</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '5', 'numOutputBytes': '2254...</td>\n",
       "      <td>add age column</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-20 22:46:07.823</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-20 22:45:53.184</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '2', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:45:34.193</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '3', 'numOutputBytes': '1880...</td>\n",
       "      <td>some comments</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName operation  \\\n",
       "0        5 2022-02-20 22:56:30.573   None     None     MERGE   \n",
       "1        4 2022-02-20 22:50:27.894   None     None     WRITE   \n",
       "2        3 2022-02-20 22:48:36.639   None     None     WRITE   \n",
       "3        2 2022-02-20 22:46:07.823   None     None     MERGE   \n",
       "4        1 2022-02-20 22:45:53.184   None     None     MERGE   \n",
       "5        0 2022-02-20 22:45:34.193   None     None     WRITE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "1         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "2            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n",
       "3  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "4  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "5         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          4.0   Serializable          False   \n",
       "1          3.0   Serializable          False   \n",
       "2          2.0   Serializable          False   \n",
       "3          1.0   Serializable          False   \n",
       "4          0.0   Serializable          False   \n",
       "5          NaN   Serializable          False   \n",
       "\n",
       "                                    operationMetrics    userMetadata  \\\n",
       "0  {'numOutputRows': '7', 'numTargetRowsInserted'...            None   \n",
       "1  {'numOutputRows': '10', 'numOutputBytes': '243...  add age column   \n",
       "2  {'numOutputRows': '5', 'numOutputBytes': '2254...  add age column   \n",
       "3  {'numOutputRows': '1', 'numTargetRowsInserted'...            None   \n",
       "4  {'numOutputRows': '2', 'numTargetRowsInserted'...            None   \n",
       "5  {'numOutputRows': '3', 'numOutputBytes': '1880...   some comments   \n",
       "\n",
       "                            engineInfo  \n",
       "0  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "1  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "2  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "3  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "4  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "5  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.forPath(spark, \"/delta-lake/users\").history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04e35a2a-cb36-4545-b59d-7984f4e21983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at   age\n",
       "0   1   Alice  2022-01-02    30\n",
       "1   1   Alice  2022-01-02    30\n",
       "2   2   Braga  2022-02-02  None\n",
       "3   3   Steve  2022-03-03  None\n",
       "4   4  Carell  2022-04-04  None\n",
       "5   4  Carell  2022-04-04  None\n",
       "6   5    Joao        None  None\n",
       "7   2   Braga  2022-02-02  None\n",
       "8   3   Steve  2022-03-03  None\n",
       "9   5    Joao        None  None"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.forPath(spark, \"/delta-lake/users\").toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa1401-c674-4e9a-8ecf-600b89812a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ef85b-7ca8-44a6-822f-792ddf40e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6f14c-dbfc-4e2f-a868-e26dc446e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
