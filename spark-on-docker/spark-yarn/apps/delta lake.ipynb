{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4cba42-4236-41d0-b79b-a1c3d86ed1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 15:26:38,253 INFO server.AbstractConnector: Stopped Spark@2218bd55{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "2022-11-20 15:26:38,253 INFO ui.SparkUI: Stopped Spark web UI at http://localhost:4040\n",
      "2022-11-20 15:26:38,259 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "2022-11-20 15:26:38,264 INFO memory.MemoryStore: MemoryStore cleared\n",
      "2022-11-20 15:26:38,264 INFO storage.BlockManager: BlockManager stopped\n",
      "2022-11-20 15:26:38,264 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "2022-11-20 15:26:38,264 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "2022-11-20 15:26:38,291 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "2022-11-20 15:26:38,817 INFO spark.SparkContext: Running Spark version 3.3.1\n",
      "2022-11-20 15:26:38,817 INFO resource.ResourceUtils: ==============================================================\n",
      "2022-11-20 15:26:38,817 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\n",
      "2022-11-20 15:26:38,818 INFO resource.ResourceUtils: ==============================================================\n",
      "2022-11-20 15:26:38,818 INFO spark.SparkContext: Submitted application: Delta Lake\n",
      "2022-11-20 15:26:38,818 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "2022-11-20 15:26:38,818 INFO resource.ResourceProfile: Limiting resource is cpu\n",
      "2022-11-20 15:26:38,818 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\n",
      "2022-11-20 15:26:38,818 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2022-11-20 15:26:38,818 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2022-11-20 15:26:38,818 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2022-11-20 15:26:38,818 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2022-11-20 15:26:38,818 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2022-11-20 15:26:38,832 INFO util.Utils: Successfully started service 'sparkDriver' on port 39897.\n",
      "2022-11-20 15:26:38,833 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "2022-11-20 15:26:38,834 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "2022-11-20 15:26:38,834 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2022-11-20 15:26:38,834 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "2022-11-20 15:26:38,834 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "2022-11-20 15:26:38,835 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-626ce09a-d3a8-4b9a-89af-dc4ac511a92e\n",
      "2022-11-20 15:26:38,835 INFO memory.MemoryStore: MemoryStore started with capacity 1048.8 MiB\n",
      "2022-11-20 15:26:38,835 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "2022-11-20 15:26:38,838 INFO server.Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.12+7\n",
      "2022-11-20 15:26:38,839 INFO server.Server: Started @665029ms\n",
      "2022-11-20 15:26:38,840 INFO server.AbstractConnector: Started ServerConnector@765d10c2{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "2022-11-20 15:26:38,840 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "2022-11-20 15:26:38,841 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20951bd3{/,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar at spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://localhost:39897/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar at spark://localhost:39897/jars/io.delta_delta-core_2.12-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar at spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar at spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar at spark://localhost:39897/jars/com.amazonaws_jmespath-java-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://localhost:39897/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar at spark://localhost:39897/jars/commons-codec_commons-codec-1.15.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar at spark://localhost:39897/jars/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar at spark://localhost:39897/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar at spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar at spark://localhost:39897/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://localhost:39897/jars/joda-time_joda-time-2.8.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar at spark://localhost:39897/jars/org.apache.httpcomponents_httpcore-4.4.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar at spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,851 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar at spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://localhost:39897/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar at spark://localhost:39897/jars/io.delta_delta-storage-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar at spark://localhost:39897/jars/org.antlr_antlr4-runtime-4.8.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://localhost:39897/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar at file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,852 INFO util.Utils: Copying /root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-s3-1.12.161.jar\n",
      "2022-11-20 15:26:38,854 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,854 INFO util.Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.hadoop_hadoop-aws-3.3.4.jar\n",
      "2022-11-20 15:26:38,857 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar at file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,857 INFO util.Utils: Copying /root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-core_2.12-2.1.1.jar\n",
      "2022-11-20 15:26:38,861 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar at file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,861 INFO util.Utils: Copying /root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-kms-1.12.161.jar\n",
      "2022-11-20 15:26:38,862 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar at file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,862 INFO util.Utils: Copying /root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-core-1.12.161.jar\n",
      "2022-11-20 15:26:38,864 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar at file:///root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,864 INFO util.Utils: Copying /root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_jmespath-java-1.12.161.jar\n",
      "2022-11-20 15:26:38,866 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,866 INFO util.Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-logging_commons-logging-1.1.3.jar\n",
      "2022-11-20 15:26:38,867 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar at file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,868 INFO util.Utils: Copying /root/.ivy2/jars/commons-codec_commons-codec-1.15.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-codec_commons-codec-1.15.jar\n",
      "2022-11-20 15:26:38,869 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar at file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,869 INFO util.Utils: Copying /root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpclient-4.5.13.jar\n",
      "2022-11-20 15:26:38,871 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar at file:///root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,871 INFO util.Utils: Copying /root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/software.amazon.ion_ion-java-1.0.2.jar\n",
      "2022-11-20 15:26:38,873 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar at file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,873 INFO util.Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar\n",
      "2022-11-20 15:26:38,875 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar at file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,875 INFO util.Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar\n",
      "2022-11-20 15:26:38,877 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/joda-time_joda-time-2.8.1.jar at file:///root/.ivy2/jars/joda-time_joda-time-2.8.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,877 INFO util.Utils: Copying /root/.ivy2/jars/joda-time_joda-time-2.8.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/joda-time_joda-time-2.8.1.jar\n",
      "2022-11-20 15:26:38,878 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar at file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,878 INFO util.Utils: Copying /root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpcore-4.4.13.jar\n",
      "2022-11-20 15:26:38,880 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar at file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,880 INFO util.Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar\n",
      "2022-11-20 15:26:38,881 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar at file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,881 INFO util.Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-core-2.12.6.jar\n",
      "2022-11-20 15:26:38,883 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:38,883 INFO util.Utils: Copying /root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar\n",
      "2022-11-20 15:26:39,007 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,007 INFO util.Utils: Copying /root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "2022-11-20 15:26:39,009 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar at file:///root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,009 INFO util.Utils: Copying /root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-storage-2.1.1.jar\n",
      "2022-11-20 15:26:39,012 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar at file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,012 INFO util.Utils: Copying /root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.antlr_antlr4-runtime-4.8.jar\n",
      "2022-11-20 15:26:39,013 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,013 INFO util.Utils: Copying /root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.codehaus.jackson_jackson-core-asl-1.9.13.jar\n",
      "2022-11-20 15:26:39,017 INFO executor.Executor: Starting executor ID driver on host localhost\n",
      "2022-11-20 15:26:39,018 INFO executor.Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "2022-11-20 15:26:39,018 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,029 INFO util.Utils: /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar\n",
      "2022-11-20 15:26:39,031 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,031 INFO util.Utils: /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-core-2.12.6.jar\n",
      "2022-11-20 15:26:39,033 INFO executor.Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,033 INFO util.Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-logging_commons-logging-1.1.3.jar\n",
      "2022-11-20 15:26:39,035 INFO executor.Executor: Fetching file:///root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,035 INFO util.Utils: /root/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/software.amazon.ion_ion-java-1.0.2.jar\n",
      "2022-11-20 15:26:39,037 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,038 INFO util.Utils: /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar\n",
      "2022-11-20 15:26:39,040 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,040 INFO util.Utils: /root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "2022-11-20 15:26:39,042 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,042 INFO util.Utils: /root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpclient-4.5.13.jar\n",
      "2022-11-20 15:26:39,044 INFO executor.Executor: Fetching file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,044 INFO util.Utils: /root/.ivy2/jars/commons-codec_commons-codec-1.15.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-codec_commons-codec-1.15.jar\n",
      "2022-11-20 15:26:39,046 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,046 INFO util.Utils: /root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.antlr_antlr4-runtime-4.8.jar\n",
      "2022-11-20 15:26:39,047 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,047 INFO util.Utils: /root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpcore-4.4.13.jar\n",
      "2022-11-20 15:26:39,049 INFO executor.Executor: Fetching file:///root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,049 INFO util.Utils: /root/.ivy2/jars/io.delta_delta-storage-2.1.1.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-storage-2.1.1.jar\n",
      "2022-11-20 15:26:39,050 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,050 INFO util.Utils: /root/.ivy2/jars/com.amazonaws_jmespath-java-1.12.161.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_jmespath-java-1.12.161.jar\n",
      "2022-11-20 15:26:39,052 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,052 INFO util.Utils: /root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.codehaus.jackson_jackson-core-asl-1.9.13.jar\n",
      "2022-11-20 15:26:39,053 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,054 INFO util.Utils: /root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar\n",
      "2022-11-20 15:26:39,055 INFO executor.Executor: Fetching file:///root/.ivy2/jars/joda-time_joda-time-2.8.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,056 INFO util.Utils: /root/.ivy2/jars/joda-time_joda-time-2.8.1.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/joda-time_joda-time-2.8.1.jar\n",
      "2022-11-20 15:26:39,057 INFO executor.Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,058 INFO util.Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.hadoop_hadoop-aws-3.3.4.jar\n",
      "2022-11-20 15:26:39,059 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,060 INFO util.Utils: /root/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-s3-1.12.161.jar\n",
      "2022-11-20 15:26:39,061 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,062 INFO util.Utils: /root/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-core-1.12.161.jar\n",
      "2022-11-20 15:26:39,063 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,063 INFO util.Utils: /root/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-kms-1.12.161.jar\n",
      "2022-11-20 15:26:39,065 INFO executor.Executor: Fetching file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,171 INFO util.Utils: /root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar\n",
      "2022-11-20 15:26:39,173 INFO executor.Executor: Fetching file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,174 INFO util.Utils: /root/.ivy2/jars/io.delta_delta-core_2.12-2.1.1.jar has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-core_2.12-2.1.1.jar\n",
      "2022-11-20 15:26:39,176 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,178 INFO client.TransportClientFactory: Successfully created connection to localhost/127.0.0.1:39897 after 1 ms (0 ms spent in bootstraps)\n",
      "2022-11-20 15:26:39,178 INFO util.Utils: Fetching spark://localhost:39897/jars/org.apache.httpcomponents_httpclient-4.5.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp15168805641046300456.tmp\n",
      "2022-11-20 15:26:39,187 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp15168805641046300456.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpclient-4.5.13.jar\n",
      "2022-11-20 15:26:39,190 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpclient-4.5.13.jar to class loader\n",
      "2022-11-20 15:26:39,190 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,190 INFO util.Utils: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-core-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp13703487264111181789.tmp\n",
      "2022-11-20 15:26:39,191 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp13703487264111181789.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-core-2.12.6.jar\n",
      "2022-11-20 15:26:39,192 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-core-2.12.6.jar to class loader\n",
      "2022-11-20 15:26:39,192 INFO executor.Executor: Fetching spark://localhost:39897/jars/io.delta_delta-storage-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,193 INFO util.Utils: Fetching spark://localhost:39897/jars/io.delta_delta-storage-2.1.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp17543974713332637626.tmp\n",
      "2022-11-20 15:26:39,193 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp17543974713332637626.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-storage-2.1.1.jar\n",
      "2022-11-20 15:26:39,195 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-storage-2.1.1.jar to class loader\n",
      "2022-11-20 15:26:39,195 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,195 INFO util.Utils: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp3341086482072663954.tmp\n",
      "2022-11-20 15:26:39,195 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp3341086482072663954.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar\n",
      "2022-11-20 15:26:39,197 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.12.6.jar to class loader\n",
      "2022-11-20 15:26:39,197 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,197 INFO util.Utils: Fetching spark://localhost:39897/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp15949775485276092920.tmp\n",
      "2022-11-20 15:26:39,198 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp15949775485276092920.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.codehaus.jackson_jackson-core-asl-1.9.13.jar\n",
      "2022-11-20 15:26:39,199 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader\n",
      "2022-11-20 15:26:39,199 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,199 INFO util.Utils: Fetching spark://localhost:39897/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14668037121606502104.tmp\n",
      "2022-11-20 15:26:39,201 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14668037121606502104.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.hadoop_hadoop-aws-3.3.4.jar\n",
      "2022-11-20 15:26:39,203 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.hadoop_hadoop-aws-3.3.4.jar to class loader\n",
      "2022-11-20 15:26:39,203 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,203 INFO util.Utils: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp11158668932116125994.tmp\n",
      "2022-11-20 15:26:39,671 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp11158668932116125994.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar\n",
      "2022-11-20 15:26:39,692 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to class loader\n",
      "2022-11-20 15:26:39,692 INFO executor.Executor: Fetching spark://localhost:39897/jars/commons-codec_commons-codec-1.15.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,693 INFO util.Utils: Fetching spark://localhost:39897/jars/commons-codec_commons-codec-1.15.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp10146182059476475870.tmp\n",
      "2022-11-20 15:26:39,694 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp10146182059476475870.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-codec_commons-codec-1.15.jar\n",
      "2022-11-20 15:26:39,696 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-codec_commons-codec-1.15.jar to class loader\n",
      "2022-11-20 15:26:39,696 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,696 INFO util.Utils: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-s3-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp5307274277954304947.tmp\n",
      "2022-11-20 15:26:39,699 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp5307274277954304947.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-s3-1.12.161.jar\n",
      "2022-11-20 15:26:39,701 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-s3-1.12.161.jar to class loader\n",
      "2022-11-20 15:26:39,701 INFO executor.Executor: Fetching spark://localhost:39897/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,701 INFO util.Utils: Fetching spark://localhost:39897/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp9551442129715763157.tmp\n",
      "2022-11-20 15:26:39,701 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp9551442129715763157.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-logging_commons-logging-1.1.3.jar\n",
      "2022-11-20 15:26:39,703 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/commons-logging_commons-logging-1.1.3.jar to class loader\n",
      "2022-11-20 15:26:39,703 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.amazonaws_jmespath-java-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,703 INFO util.Utils: Fetching spark://localhost:39897/jars/com.amazonaws_jmespath-java-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp4589549784670335851.tmp\n",
      "2022-11-20 15:26:39,704 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp4589549784670335851.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_jmespath-java-1.12.161.jar\n",
      "2022-11-20 15:26:39,705 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_jmespath-java-1.12.161.jar to class loader\n",
      "2022-11-20 15:26:39,705 INFO executor.Executor: Fetching spark://localhost:39897/jars/joda-time_joda-time-2.8.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,705 INFO util.Utils: Fetching spark://localhost:39897/jars/joda-time_joda-time-2.8.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp10420421241620577345.tmp\n",
      "2022-11-20 15:26:39,707 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp10420421241620577345.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/joda-time_joda-time-2.8.1.jar\n",
      "2022-11-20 15:26:39,708 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/joda-time_joda-time-2.8.1.jar to class loader\n",
      "2022-11-20 15:26:39,708 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,708 INFO util.Utils: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp1621940815951834310.tmp\n",
      "2022-11-20 15:26:39,709 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp1621940815951834310.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar\n",
      "2022-11-20 15:26:39,710 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-annotations-2.12.6.jar to class loader\n",
      "2022-11-20 15:26:39,710 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.antlr_antlr4-runtime-4.8.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,710 INFO util.Utils: Fetching spark://localhost:39897/jars/org.antlr_antlr4-runtime-4.8.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp4477408259142768901.tmp\n",
      "2022-11-20 15:26:39,712 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp4477408259142768901.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.antlr_antlr4-runtime-4.8.jar\n",
      "2022-11-20 15:26:39,713 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.antlr_antlr4-runtime-4.8.jar to class loader\n",
      "2022-11-20 15:26:39,713 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,713 INFO util.Utils: Fetching spark://localhost:39897/jars/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp7215318319205583480.tmp\n",
      "2022-11-20 15:26:39,715 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp7215318319205583480.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar\n",
      "2022-11-20 15:26:39,717 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.fasterxml.jackson.core_jackson-databind-2.12.6.jar to class loader\n",
      "2022-11-20 15:26:39,717 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,717 INFO util.Utils: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-core-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp2016889350354124958.tmp\n",
      "2022-11-20 15:26:39,719 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp2016889350354124958.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-core-1.12.161.jar\n",
      "2022-11-20 15:26:39,721 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-core-1.12.161.jar to class loader\n",
      "2022-11-20 15:26:39,721 INFO executor.Executor: Fetching spark://localhost:39897/jars/io.delta_delta-core_2.12-2.1.1.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,721 INFO util.Utils: Fetching spark://localhost:39897/jars/io.delta_delta-core_2.12-2.1.1.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14657784055652774335.tmp\n",
      "2022-11-20 15:26:39,725 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14657784055652774335.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-core_2.12-2.1.1.jar\n",
      "2022-11-20 15:26:39,727 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/io.delta_delta-core_2.12-2.1.1.jar to class loader\n",
      "2022-11-20 15:26:39,727 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,727 INFO util.Utils: Fetching spark://localhost:39897/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14771265665528725211.tmp\n",
      "2022-11-20 15:26:39,728 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp14771265665528725211.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "2022-11-20 15:26:39,729 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to class loader\n",
      "2022-11-20 15:26:39,729 INFO executor.Executor: Fetching spark://localhost:39897/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,730 INFO util.Utils: Fetching spark://localhost:39897/jars/software.amazon.ion_ion-java-1.0.2.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp11536992056722514374.tmp\n",
      "2022-11-20 15:26:39,731 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp11536992056722514374.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/software.amazon.ion_ion-java-1.0.2.jar\n",
      "2022-11-20 15:26:39,732 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/software.amazon.ion_ion-java-1.0.2.jar to class loader\n",
      "2022-11-20 15:26:39,733 INFO executor.Executor: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,733 INFO util.Utils: Fetching spark://localhost:39897/jars/com.amazonaws_aws-java-sdk-kms-1.12.161.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp8392988237277159538.tmp\n",
      "2022-11-20 15:26:39,734 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp8392988237277159538.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-kms-1.12.161.jar\n",
      "2022-11-20 15:26:39,736 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/com.amazonaws_aws-java-sdk-kms-1.12.161.jar to class loader\n",
      "2022-11-20 15:26:39,736 INFO executor.Executor: Fetching spark://localhost:39897/jars/org.apache.httpcomponents_httpcore-4.4.13.jar with timestamp 1668957998817\n",
      "2022-11-20 15:26:39,736 INFO util.Utils: Fetching spark://localhost:39897/jars/org.apache.httpcomponents_httpcore-4.4.13.jar to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp17333276073134203519.tmp\n",
      "2022-11-20 15:26:39,737 INFO util.Utils: /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/fetchFileTemp17333276073134203519.tmp has been previously copied to /tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpcore-4.4.13.jar\n",
      "2022-11-20 15:26:39,738 INFO executor.Executor: Adding file:/tmp/spark-d9aee0c2-930d-499f-83cd-f1534728900b/userFiles-fa2e6af2-9bea-4f72-ae6c-0868238ac53c/org.apache.httpcomponents_httpcore-4.4.13.jar to class loader\n",
      "2022-11-20 15:26:39,740 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46105.\n",
      "2022-11-20 15:26:39,740 INFO netty.NettyBlockTransferService: Server created on localhost:46105\n",
      "2022-11-20 15:26:39,740 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2022-11-20 15:26:39,740 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 46105, None)\n",
      "2022-11-20 15:26:39,740 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:46105 with 1048.8 MiB RAM, BlockManagerId(driver, localhost, 46105, None)\n",
      "2022-11-20 15:26:39,740 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 46105, None)\n",
      "2022-11-20 15:26:39,740 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 46105, None)\n",
      "2022-11-20 15:26:39,743 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@20951bd3{/,null,STOPPED,@Spark}\n",
      "2022-11-20 15:26:39,743 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53e7d516{/jobs,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,743 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22153897{/jobs/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,743 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6606bea6{/jobs/job,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2815476a{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54932b0a{/stages,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@dbbf4b1{/stages/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d252441{/stages/stage,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3e2e1a36{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,744 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@464394ca{/stages/pool,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,745 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@77c44a8a{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,745 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a3333bd{/storage,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,745 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed3c7e9{/storage/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,745 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7d0765b8{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,745 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4647378{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,746 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c74ec66{/environment,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,746 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f240c9b{/environment/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,746 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6db8d517{/executors,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,746 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@80b73f1{/executors/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,747 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2581ab2e{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,747 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36f80952{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,748 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@465658e0{/static,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,748 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ee49a18{/,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,748 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64d9626{/api,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,748 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61ceb26d{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,748 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6743b037{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,749 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a4d4442{/metrics/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,789 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "2022-11-20 15:26:39,790 INFO internal.SharedState: Warehouse path is 'file:/opt/apps/spark-warehouse'.\n",
      "2022-11-20 15:26:39,790 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@578ba99b{/SQL,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,791 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47f4ead1{/SQL/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,791 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e772b{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,791 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2916e1ae{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "2022-11-20 15:26:39,792 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a6097d7{/static/sql,null,AVAILABLE,@Spark}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Delta Lake</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f689f7cb9d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "config = SparkConf() \\\n",
    "                    .setAppName('Delta Lake') \\\n",
    "                    .setAll([('spark.executor.memory', '4G'),\n",
    "                            ('spark.driver.memory', '2G'),\n",
    "                            ('spark.driver.maxResultSize', '1G')]) \\\n",
    "                    .set(\"spark.jars.packages\", \"com.amazonaws:aws-java-sdk-s3:1.12.161,org.apache.hadoop:hadoop-aws:3.3.4,io.delta:delta-core_2.12:2.1.1\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.name\", \"directory\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.staging.conflict-mode\", \"replace\") \\\n",
    "                    .set(\"spark.hadoop.fs.s3a.committer.staging.tmp.path\", \"/tmp/staging\") \\\n",
    "                    .set(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                    .set(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "sc = SparkContext(conf=config)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# spark = SparkSession.builder.config(conf=config)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9857b07a-9017-4436-980e-f497aa2808c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "from pyspark.sql.functions import lit\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d12971-9370-43a3-b7d5-e99a09e72125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   1  Alice  2022-01-01\n",
       "1   2  Braga  2022-02-02\n",
       "2   3  Steve  2022-03-03"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  [{'id': 1, 'name': 'Alice', 'updated_at': datetime(2022, 1, 1)},\n",
    "         {'id': 2, 'name': 'Braga', 'updated_at': datetime(2022, 2, 2)},\n",
    "         {'id': 3, 'name': 'Steve', 'updated_at': datetime(2022, 3, 3)}]\n",
    "\n",
    "schema = StructType([StructField('id', IntegerType(), nullable=True),\n",
    "                     StructField('name', StringType(), nullable=True),\n",
    "                     StructField('updated_at', DateType(), nullable=True)])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4acc7-980e-480d-970a-d745e8928ca3",
   "metadata": {},
   "source": [
    "## Create Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4feef-a3c2-4ae4-aa1d-defc6759f067",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e926c632-bc4b-498a-828b-d708ba5f879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create or replace partitioned table with path using DataFrame's schema and write/overwrite data to it\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"userMetadata\", \"some comments\") \\\n",
    "  .save(\"/delta-lake/users\")\n",
    "\n",
    "# Create table in the metastore using DataFrame's schema and write data to it\n",
    "# df.write.format(\"delta\") \\\n",
    "#   .mode(\"overwrite\") \\\n",
    "#   .option(\"mergeSchema\", \"true\") \\\n",
    "#   .saveAsTable(\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732cae1-0263-4085-a76a-c29e5ca67bb4",
   "metadata": {},
   "source": [
    "### Minio (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fe19d-24ab-4b8e-95b7-61bc67dbb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .save(\"s3a://my-bucket//delta-lake/users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7523a0-fffd-4330-8d92-efa7775e9c47",
   "metadata": {},
   "source": [
    "### Create table without data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6be46f-e6a8-45ef-884a-a3eb6ad12e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_table = DeltaTable.createOrReplace(spark) \\\n",
    "  .addColumn(\"id\", \"INT\") \\\n",
    "  .addColumn(\"firstName\", \"STRING\") \\\n",
    "  .addColumn(\"middleName\", \"STRING\") \\\n",
    "  .addColumn(\"lastName\", \"STRING\", comment = \"surname\") \\\n",
    "  .addColumn(\"gender\", \"STRING\") \\\n",
    "  .addColumn(\"birthDate\", \"TIMESTAMP\") \\\n",
    "  .addColumn(\"ssn\", \"STRING\") \\\n",
    "  .addColumn(\"salary\", \"INT\") \\\n",
    "  .property(\"description\", \"table with people data\") \\\n",
    "  .location(\"/delta-lake/my-table\") \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc711eee-64f6-4350-a6d6-1226c63e6e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:04:09.548</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName                operation  \\\n",
       "0        0 2022-02-20 22:04:09.548   None     None  CREATE OR REPLACE TABLE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "\n",
       "   readVersion     isolationLevel  isBlindAppend operationMetrics  \\\n",
       "0          NaN  SnapshotIsolation           True               {}   \n",
       "\n",
       "  userMetadata                           engineInfo  \n",
       "0         None  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as delta format\n",
    "my_table = DeltaTable.forPath(spark, \"/delta-lake/my-table\")\n",
    "my_table.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e072f4c8-5eec-40a9-931a-9acc0163488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>ssn</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, firstName, middleName, lastName, gender, birthDate, ssn, salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970952c-57ff-4437-bfa3-bf5299ead1f3",
   "metadata": {},
   "source": [
    "## Read Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4632ca-ceed-4d81-b543-872334e4f5f9",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "666726ce-9a41-4283-aac7-3aadb4ebe785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as delta format\n",
    "spark.read.format(\"delta\") \\\n",
    "     .load(\"/delta-lake/users\") \\\n",
    "     .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248a9123-9c17-445f-9576-6b81e198822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM delta.`/delta-lake/users` -- query table by path\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ab76a7-7e28-4b53-9925-ca03c9fcfc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03\n",
       "4   1   Alice  2022-01-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as parquet format\n",
    "spark.read.format(\"parquet\") \\\n",
    "     .load(\"/delta-lake/users\") \\\n",
    "     .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c55f6-5592-4e94-8d06-2d1bd2c13598",
   "metadata": {},
   "source": [
    "### Minio (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43a136-14e2-49b9-8264-8108cffb4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\") \\\n",
    "     .load(\"s3a://my-bucket/delta-lake/users\") \\\n",
    "     .toPandas()\n",
    "\n",
    "# spark.read.format(\"parquet\") \\\n",
    "#      .load(\"s3a://my-bucket//delta-lake/users\") \\\n",
    "#      .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a04777-5946-4af7-a1cd-728e4bd736a4",
   "metadata": {},
   "source": [
    "## Describe tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c458d1e-d49b-403f-88dc-ec039a3b3585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-20 22:11:18.529</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '2', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:03:47.787</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '3', 'numOutputBytes': '1880...</td>\n",
       "      <td>some comments</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName operation  \\\n",
       "0        1 2022-02-20 22:11:18.529   None     None     MERGE   \n",
       "1        0 2022-02-20 22:03:47.787   None     None     WRITE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "1         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          0.0   Serializable          False   \n",
       "1          NaN   Serializable          False   \n",
       "\n",
       "                                    operationMetrics   userMetadata  \\\n",
       "0  {'numOutputRows': '2', 'numTargetRowsInserted'...           None   \n",
       "1  {'numOutputRows': '3', 'numOutputBytes': '1880...  some comments   \n",
       "\n",
       "                            engineInfo  \n",
       "0  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "1  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table = DeltaTable.forPath(spark, \"/delta-lake/users\")\n",
    "users_table.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d62bbc-f2bb-4cb9-abf8-ddec32098130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>partitionColumns</th>\n",
       "      <th>numFiles</th>\n",
       "      <th>sizeInBytes</th>\n",
       "      <th>properties</th>\n",
       "      <th>minReaderVersion</th>\n",
       "      <th>minWriterVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>0b8f1ca3-c7bf-4740-89ea-678beefb4baf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>hdfs://localhost:9000/delta-lake/users</td>\n",
       "      <td>2022-02-20 22:03:45.023</td>\n",
       "      <td>2022-02-20 22:03:47.787</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1880</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  format                                    id  name description  \\\n",
       "0  delta  0b8f1ca3-c7bf-4740-89ea-678beefb4baf  None        None   \n",
       "\n",
       "                                 location               createdAt  \\\n",
       "0  hdfs://localhost:9000/delta-lake/users 2022-02-20 22:03:45.023   \n",
       "\n",
       "             lastModified partitionColumns  numFiles  sizeInBytes properties  \\\n",
       "0 2022-02-20 22:03:47.787               []         2         1880         {}   \n",
       "\n",
       "   minReaderVersion  minWriterVersion  \n",
       "0                 1                 2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    DESCRIBE DETAIL delta.`/delta-lake/users` -- query table by path\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eaf45c1-e02f-450d-a184-312c7b845463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>partitionColumns</th>\n",
       "      <th>numFiles</th>\n",
       "      <th>sizeInBytes</th>\n",
       "      <th>properties</th>\n",
       "      <th>minReaderVersion</th>\n",
       "      <th>minWriterVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>931b0889-4c4f-4f45-98aa-d64052cb5fbd</td>\n",
       "      <td>default.users</td>\n",
       "      <td>None</td>\n",
       "      <td>file:/opt/apps/spark-warehouse/users</td>\n",
       "      <td>2022-02-20 18:40:31.589</td>\n",
       "      <td>2022-02-20 22:03:55.757</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1880</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  format                                    id           name description  \\\n",
       "0  delta  931b0889-4c4f-4f45-98aa-d64052cb5fbd  default.users        None   \n",
       "\n",
       "                               location               createdAt  \\\n",
       "0  file:/opt/apps/spark-warehouse/users 2022-02-20 18:40:31.589   \n",
       "\n",
       "             lastModified partitionColumns  numFiles  sizeInBytes properties  \\\n",
       "0 2022-02-20 22:03:55.757               []         2         1880         {}   \n",
       "\n",
       "   minReaderVersion  minWriterVersion  \n",
       "0                 1                 2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only if delta table saved as table\n",
    "spark.sql(\"\"\"\n",
    "    DESCRIBE DETAIL users\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abb906c-113f-4381-9dee-81bf8db7325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  updated_at\n",
       "0   2  Braga  2022-02-02\n",
       "1   3  Steve  2022-03-03\n",
       "2   1  Alice  2022-01-01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only if delta table saved as table\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM users\n",
    "    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fef1c17-cf1f-43d2-91d3-1e039f4965fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>users</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace tableName  isTemporary\n",
       "0   default     users        False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tables in metastore\n",
    "spark.sql(\"\"\"\n",
    "    SHOW tables\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305931e-7ed5-4718-a8e9-ba7e33c8d546",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upsert (Merge) new Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "64cf4061-8e7f-47a6-a660-a3df43a3cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = DeltaTable.forPath(spark, \"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa5f0de7-2a33-4252-9546-bcf430b65eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [{'id': 1, 'name': 'Alice', 'updated_at': datetime(2022, 1, 2)},\n",
    "            {'id': 4, 'name': 'Carell', 'updated_at': datetime(2022, 4, 4)}]\n",
    "\n",
    "new_data_df = spark.createDataFrame(new_data, schema=schema)\n",
    "new_data_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9c6ae-dde1-4496-92a1-37035b5f19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=new_data_df.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdate(set={\n",
    "                                    \"updated_at\": \"new_data.updated_at\"\n",
    "                              }) \\\n",
    "           .whenNotMatchedInsert(values={\n",
    "                                            \"id\": \"new_data.id\",\n",
    "                                            \"name\": \"new_data.name\",\n",
    "                                            \"updated_at\": \"new_data.updated_at\"\n",
    "                                }) \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4fdc734b-fdf6-4bf3-88bf-187b82ca1823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=new_data_df.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdateAll() \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643ffa3-eb70-4d1b-aa40-9f5cce722bfc",
   "metadata": {},
   "source": [
    "### Upsert with Missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad4dcdf9-4c82-4121-bafc-8d7f4b4efc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  name updated_at\n",
       "0   5  Joao       None"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_missing_fields = [{\"id\": 5, 'name': 'Joao'}]\n",
    "\n",
    "data_missing_fields = spark.createDataFrame(data_missing_fields, schema=schema)\n",
    "data_missing_fields.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5db6fe9d-b5d2-481a-94da-c39d3befe469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at\n",
       "0   1   Alice  2022-01-02\n",
       "1   4  Carell  2022-04-04\n",
       "2   2   Braga  2022-02-02\n",
       "3   3   Steve  2022-03-03\n",
       "4   5    Joao        None"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.alias(\"old_data\") \\\n",
    "           .merge(source=data_missing_fields.alias(\"new_data\"), condition=\"old_data.id = new_data.id\") \\\n",
    "           .whenMatchedUpdateAll() \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()\n",
    "\n",
    "users_table.toDF().limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f9daf-02e6-47e2-9786-12e0d0bbd34f",
   "metadata": {},
   "source": [
    "## Update Schema adding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2d5f5af-9f60-4d8f-b884-a99bc23ad1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as delta format\n",
    "update_schema = spark.read.format(\"delta\").load(\"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d3ae7ed-ee12-4b0b-81fa-fb867365391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- updated_at: date (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add column\n",
    "update_schema = update_schema.withColumn(\"age\", lit(None).cast(StringType()))\n",
    "update_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8578df30-87c7-4ae8-94b6-c2777d7d945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at   age\n",
       "0   1   Alice  2022-01-02  None\n",
       "1   4  Carell  2022-04-04  None\n",
       "2   2   Braga  2022-02-02  None\n",
       "3   3   Steve  2022-03-03  None\n",
       "4   5    Joao        None  None"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_schema.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58afc83e-32f3-4ebc-af7f-13af7bb4ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Merge Schema, another option is overwriteSchema\n",
    "update_schema.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .option(\"userMetadata\", \"add age column\") \\\n",
    "  .save(\"/delta-lake/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74698b00-c46f-4ebc-81b0-5a138c0f4bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-02-20 22:56:30.573</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '7', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-20 22:50:27.894</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '10', 'numOutputBytes': '243...</td>\n",
       "      <td>add age column</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-20 22:48:36.639</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '5', 'numOutputBytes': '2254...</td>\n",
       "      <td>add age column</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-20 22:46:07.823</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-20 22:45:53.184</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '2', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-20 22:45:34.193</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '3', 'numOutputBytes': '1880...</td>\n",
       "      <td>some comments</td>\n",
       "      <td>Apache-Spark/3.2.1 Delta-Lake/1.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName operation  \\\n",
       "0        5 2022-02-20 22:56:30.573   None     None     MERGE   \n",
       "1        4 2022-02-20 22:50:27.894   None     None     WRITE   \n",
       "2        3 2022-02-20 22:48:36.639   None     None     WRITE   \n",
       "3        2 2022-02-20 22:46:07.823   None     None     MERGE   \n",
       "4        1 2022-02-20 22:45:53.184   None     None     MERGE   \n",
       "5        0 2022-02-20 22:45:34.193   None     None     WRITE   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "1         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "2            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n",
       "3  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "4  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n",
       "5         {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          4.0   Serializable          False   \n",
       "1          3.0   Serializable          False   \n",
       "2          2.0   Serializable          False   \n",
       "3          1.0   Serializable          False   \n",
       "4          0.0   Serializable          False   \n",
       "5          NaN   Serializable          False   \n",
       "\n",
       "                                    operationMetrics    userMetadata  \\\n",
       "0  {'numOutputRows': '7', 'numTargetRowsInserted'...            None   \n",
       "1  {'numOutputRows': '10', 'numOutputBytes': '243...  add age column   \n",
       "2  {'numOutputRows': '5', 'numOutputBytes': '2254...  add age column   \n",
       "3  {'numOutputRows': '1', 'numTargetRowsInserted'...            None   \n",
       "4  {'numOutputRows': '2', 'numTargetRowsInserted'...            None   \n",
       "5  {'numOutputRows': '3', 'numOutputBytes': '1880...   some comments   \n",
       "\n",
       "                            engineInfo  \n",
       "0  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "1  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "2  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "3  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "4  Apache-Spark/3.2.1 Delta-Lake/1.1.0  \n",
       "5  Apache-Spark/3.2.1 Delta-Lake/1.1.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.forPath(spark, \"/delta-lake/users\").history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04e35a2a-cb36-4545-b59d-7984f4e21983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Carell</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Braga</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Joao</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name  updated_at   age\n",
       "0   1   Alice  2022-01-02    30\n",
       "1   1   Alice  2022-01-02    30\n",
       "2   2   Braga  2022-02-02  None\n",
       "3   3   Steve  2022-03-03  None\n",
       "4   4  Carell  2022-04-04  None\n",
       "5   4  Carell  2022-04-04  None\n",
       "6   5    Joao        None  None\n",
       "7   2   Braga  2022-02-02  None\n",
       "8   3   Steve  2022-03-03  None\n",
       "9   5    Joao        None  None"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.forPath(spark, \"/delta-lake/users\").toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa1401-c674-4e9a-8ecf-600b89812a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ef85b-7ca8-44a6-822f-792ddf40e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6f14c-dbfc-4e2f-a868-e26dc446e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
