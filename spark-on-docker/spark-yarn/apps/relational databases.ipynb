{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e26607e-1429-42e5-b2c1-ca4c8ddfaffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-without-hadoop/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.mysql#mysql-connector-j added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4a846a7e-9ddc-4130-b38b-dc423006f8c8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.mysql#mysql-connector-j;9.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;4.26.1 in central\n",
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/9.0.0/mysql-connector-j-9.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.mysql#mysql-connector-j;9.0.0!mysql-connector-j.jar (1113ms)\n",
      "downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.3/postgresql-42.7.3.jar ...\n",
      "\t[SUCCESSFUL ] org.postgresql#postgresql;42.7.3!postgresql.jar (314ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/4.26.1/protobuf-java-4.26.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;4.26.1!protobuf-java.jar (342ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.42.0/checker-qual-3.42.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.42.0!checker-qual.jar (278ms)\n",
      ":: resolution report :: resolve 5502ms :: artifacts dl 2055ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;4.26.1 from central in [default]\n",
      "\tcom.mysql#mysql-connector-j;9.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   4   |   4   |   0   ||   4   |   4   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4a846a7e-9ddc-4130-b38b-dc423006f8c8\n",
      "\tconfs: [default]\n",
      "\t4 artifacts copied, 0 already retrieved (5568kB/18ms)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Connect to Relational databases</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff6cb73310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Connect to Relational databases\") \\\n",
    "                    .config(\"spark.executor.memory\", \"1G\") \\\n",
    "                    .config(\"spark.driver.memory\", \"1G\") \\\n",
    "                    .config(\"spark.driver.maxResultSize\", \"1G\") \\\n",
    "                    .config(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:9.0.0,org.postgresql:postgresql:42.7.3\") \\\n",
    "                    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "                    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57439da-f6ba-4332-8680-0dca0d896390",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093c11c7-0133-439b-b5c2-8ef2079eb579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-------------------+\n",
      "|actor_id|first_name|   last_name|        last_update|\n",
      "+--------+----------+------------+-------------------+\n",
      "|       1|  PENELOPE|     GUINESS|2006-02-15 04:34:33|\n",
      "|       2|      NICK|    WAHLBERG|2006-02-15 04:34:33|\n",
      "|       3|        ED|       CHASE|2006-02-15 04:34:33|\n",
      "|       4|  JENNIFER|       DAVIS|2006-02-15 04:34:33|\n",
      "|       5|    JOHNNY|LOLLOBRIGIDA|2006-02-15 04:34:33|\n",
      "|       6|     BETTE|   NICHOLSON|2006-02-15 04:34:33|\n",
      "|       7|     GRACE|      MOSTEL|2006-02-15 04:34:33|\n",
      "|       8|   MATTHEW|   JOHANSSON|2006-02-15 04:34:33|\n",
      "|       9|       JOE|       SWANK|2006-02-15 04:34:33|\n",
      "|      10| CHRISTIAN|       GABLE|2006-02-15 04:34:33|\n",
      "|      11|      ZERO|        CAGE|2006-02-15 04:34:33|\n",
      "|      12|      KARL|       BERRY|2006-02-15 04:34:33|\n",
      "|      13|       UMA|        WOOD|2006-02-15 04:34:33|\n",
      "|      14|    VIVIEN|      BERGEN|2006-02-15 04:34:33|\n",
      "|      15|      CUBA|     OLIVIER|2006-02-15 04:34:33|\n",
      "|      16|      FRED|     COSTNER|2006-02-15 04:34:33|\n",
      "|      17|     HELEN|      VOIGHT|2006-02-15 04:34:33|\n",
      "|      18|       DAN|        TORN|2006-02-15 04:34:33|\n",
      "|      19|       BOB|     FAWCETT|2006-02-15 04:34:33|\n",
      "|      20|   LUCILLE|       TRACY|2006-02-15 04:34:33|\n",
      "+--------+----------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "200\n",
      "root\n",
      " |-- actor_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the JDBC connection\n",
    "jdbc_url = \"jdbc:mysql://mysql:3306/sakila\"\n",
    "connection_properties = {\n",
    "      \"user\" : \"root\",\n",
    "      \"password\" : \"root\",\n",
    "      \"driver\" : \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "\n",
    "# Create a query\n",
    "query = \"\"\"\n",
    "            SELECT * FROM actor\n",
    "        \"\"\"\n",
    "\n",
    "# run the query\n",
    "bh_bairros_df = spark.read \\\n",
    "                     .jdbc(url=jdbc_url, \n",
    "                           table=f\"({query}) AS t\", \n",
    "                           properties=connection_properties)\n",
    "\n",
    "bh_bairros_df.show()\n",
    "print(bh_bairros_df.count())\n",
    "bh_bairros_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0352cde0-f10d-40bd-a7d7-c2a3e8b61beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actor_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bh_bairros_df.write \\\n",
    "             .mode(\"overwrite\") \\\n",
    "             .option(\"truncate\", \"true\") \\\n",
    "             .jdbc(url=jdbc_url, \n",
    "                   table=\"new_table\",\n",
    "                   properties=connection_properties)\n",
    "\n",
    "bh_bairros_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538f507-1214-43ea-bd8a-7c1fc1d6f659",
   "metadata": {},
   "source": [
    "# Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a43e76b-ee63-4137-8d16-de9cb121ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+------+--------------------+\n",
      "|                  id|              name|              amount| price|       id_categories|\n",
      "+--------------------+------------------+--------------------+------+--------------------+\n",
      "|1.000000000000000000|         Lampshade|100.0000000000000...|800.00|4.000000000000000000|\n",
      "|2.000000000000000000|Table for painting|1000.000000000000...|560.00|9.000000000000000000|\n",
      "|3.000000000000000000|     Notebook desk|10000.00000000000...| 25.50|9.000000000000000000|\n",
      "|4.000000000000000000|     Computer desk|350.0000000000000...|320.50|6.000000000000000000|\n",
      "|5.000000000000000000|             Chair|3000.000000000000...|210.64|9.000000000000000000|\n",
      "|6.000000000000000000|        Home alarm|750.0000000000000...|460.00|4.000000000000000000|\n",
      "+--------------------+------------------+--------------------+------+--------------------+\n",
      "\n",
      "6\n",
      "root\n",
      " |-- id: decimal(38,18) (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- amount: decimal(38,18) (nullable = true)\n",
      " |-- price: decimal(7,2) (nullable = true)\n",
      " |-- id_categories: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the JDBC connection\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/mydb\"\n",
    "connection_properties = {\n",
    "      \"user\" : \"user\",\n",
    "      \"password\" : \"pass\",\n",
    "      \"driver\" : \"org.postgresql.Driver\"\n",
    "    }\n",
    "\n",
    "# Create a query\n",
    "query = \"\"\"\n",
    "            SELECT * FROM products\n",
    "        \"\"\"\n",
    "\n",
    "# run the query\n",
    "df = spark.read \\\n",
    "                     .jdbc(url=jdbc_url, \n",
    "                           table=f\"({query}) AS t\", \n",
    "                           properties=connection_properties)\n",
    "\n",
    "df.show()\n",
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7b1dfe-6503-4b3b-ba90-037a0d598ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: decimal(38,18) (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- amount: decimal(38,18) (nullable = true)\n",
      " |-- price: decimal(7,2) (nullable = true)\n",
      " |-- id_categories: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.write \\\n",
    "     .mode(\"overwrite\") \\\n",
    "     .option(\"truncate\", \"true\") \\\n",
    "     .jdbc(url=jdbc_url, \n",
    "           table=\"new_table\",\n",
    "           properties=connection_properties)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4becb9-ea20-483a-a860-c95c24a5686b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
