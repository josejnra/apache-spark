{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4807307d-c64e-451a-b104-87ec5d06df95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Import custom jar</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff7bfd01f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Import custom jar\") \\\n",
    "                    .config(\"spark.executor.memory\", \"1G\") \\\n",
    "                    .config(\"spark.driver.memory\", \"1G\") \\\n",
    "                    .config(\"spark.driver.maxResultSize\", \"1G\") \\\n",
    "                    .config(\"spark.jars\", \"/opt/scala-project_2.12-0.1.0-SNAPSHOT.jar\") \\\n",
    "                    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "                    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40582db7-3ca5-4bcd-82a5-3f1cd305d09d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427c23e-95b5-4edb-a15c-54c97770278b",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe59a86d-53b9-4f80-9682-83dd14dca23d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name| id|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "|Braga|  2|\n",
      "|Steve|  3|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import Row, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "row_list_data = [Row('Alice', 1), Row('Braga', 2), Row('Steve', 3)]\n",
    "df = spark.createDataFrame(row_list_data, ['name', 'id'])\n",
    "\n",
    "df = df.withColumn(\"id\", col(\"id\").cast(IntegerType()))\n",
    "    \n",
    "df.createOrReplaceTempView('users')\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686830b-3931-477c-87a6-3f1987f627fa",
   "metadata": {},
   "source": [
    "## Access via SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c95214-d157-495d-b7cf-c2f49f851396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaObject id=o80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# register class that implements UDF interface\n",
    "spark.udf.registerJavaFunction(\"lowerCaseString\", \"com.myudfs.LowerCaseString\", returnType=StringType())\n",
    "\n",
    "# call register function from class MathUDFs that will register the udf in spark \n",
    "spark.sparkContext._jvm.com.myudfs.MathUDFs.registerUdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed856cf-a197-45bf-b586-73c261f43fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|isGreaterThanZero(id)| name|\n",
      "+---------------------+-----+\n",
      "|                 true|Alice|\n",
      "|                 true|Braga|\n",
      "|                 true|Steve|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT isGreaterThanZero(id), name\n",
    "    FROM users\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0bdc35-ccbc-452c-87ef-7a608e6ab248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "| id|lowerCaseString(name)|\n",
      "+---+---------------------+\n",
      "|  1|                alice|\n",
      "|  2|                braga|\n",
      "|  3|                steve|\n",
      "+---+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT id, lowerCaseString(name)\n",
    "    FROM users\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f06df1-15b9-4e29-b15e-fb8c996f20f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e438da3-6b26-4d69-97eb-01aaf0ce4586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e26549ad-0453-4d16-bc8f-1fb95c02da67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access via DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac7762e-6d07-4c5c-a0c4-6a5fe14e00b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from py4j.java_gateway import java_import\n",
    "from pyspark.sql.column import Column, _to_java_column, _to_seq \n",
    "\n",
    "def greater_than_zero_udf(df_col: str):\n",
    "    greaterThanZeroUDF = spark.sparkContext._jvm.com.myudfs.MathUDFs.isGreaterThanZeroUDF()\n",
    "    return Column(greaterThanZeroUDF.apply(_to_seq(spark.sparkContext, [df_col], _to_java_column)))\n",
    "\n",
    "def multiplier_udf(df_col: str, multiply_by: int):\n",
    "    def multiplier(df_col: str):\n",
    "        multiplierUDF = spark.sparkContext._jvm.com.myudfs.MathUDFs.multiplyBy(multiply_by)\n",
    "        return Column(multiplierUDF.apply(_to_seq(spark.sparkContext, [df_col], _to_java_column)))\n",
    "\n",
    "    return multiplier(df_col)\n",
    "\n",
    "# work in progress\n",
    "def lower_case_udf(df_col: str):\n",
    "    lower_case_class = spark.sparkContext._jvm.com.myudfs.LowerCaseString\n",
    "    return Column(lower_case_class.apply(_to_seq(spark.sparkContext, [df_col], _to_java_column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80efa0e-772d-4e0f-8f4e-ec3fff8241a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------+----------+\n",
      "| name| id|greater_than_zero|multiplied|\n",
      "+-----+---+-----------------+----------+\n",
      "|Alice|  1|             true|        10|\n",
      "|Braga|  2|             true|        20|\n",
      "|Steve|  3|             true|        30|\n",
      "+-----+---+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn(\"greater_than_zero\", greater_than_zero_udf(\"id\")) \\\n",
    "    .withColumn(\"multiplied\", multiplier_udf(\"id\", 10)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539455e1-547a-4785-b126-28298425cb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
