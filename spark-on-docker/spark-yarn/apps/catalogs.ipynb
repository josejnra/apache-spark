{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aebfbd1-20e0-4591-93de-dd25c01f05cc",
   "metadata": {},
   "source": [
    "## In Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5fd0c-dc64-4294-83b5-b5db53283afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"In memory catalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-hive_2.12:3.5.1\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1273c4ef-520b-43c6-9782-0222fcd902fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark_catalog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         catalog\n",
       "0  spark_catalog"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW catalogs\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814467e7-f8ed-4ca6-aba9-c61367718ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS mydb\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16eaf19-00c3-45b3-a9a5-70b32ec9e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mydb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace\n",
       "0   default\n",
       "1      mydb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW databases\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95a21ef-f9ed-459e-b271-741c8743d81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [namespace, tableName, isTemporary]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW tables\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51749685-bea9-4c35-8b59-fd516c776510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE mydb.local_table (\n",
    "    id INT COMMENT 'Identificador único',\n",
    "    name STRING COMMENT 'Nome do indivíduo'\n",
    ") USING hive\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c7050a-7aed-4868-bb9d-049f5a93aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int</td>\n",
       "      <td>Identificador único</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>string</td>\n",
       "      <td>Nome do indivíduo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catalog</td>\n",
       "      <td>spark_catalog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Database</td>\n",
       "      <td>mydb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Table</td>\n",
       "      <td>local_table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Owner</td>\n",
       "      <td>root</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Created Time</td>\n",
       "      <td>Tue Aug 13 18:14:55 UTC 2024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Last Access</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Created By</td>\n",
       "      <td>Spark 3.5.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Provider</td>\n",
       "      <td>hive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[transient_lastDdlTime=1723572895]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Location</td>\n",
       "      <td>file:/opt/apps/spark-warehouse/mydb.db/local_t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Serde Library</td>\n",
       "      <td>org.apache.hadoop.hive.serde2.lazy.LazySimpleS...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InputFormat</td>\n",
       "      <td>org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OutputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyText...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Storage Properties</td>\n",
       "      <td>[serialization.format=1]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Partition Provider</td>\n",
       "      <td>Catalog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  \\\n",
       "0                             id   \n",
       "1                           name   \n",
       "2                                  \n",
       "3   # Detailed Table Information   \n",
       "4                        Catalog   \n",
       "5                       Database   \n",
       "6                          Table   \n",
       "7                          Owner   \n",
       "8                   Created Time   \n",
       "9                    Last Access   \n",
       "10                    Created By   \n",
       "11                          Type   \n",
       "12                      Provider   \n",
       "13              Table Properties   \n",
       "14                      Location   \n",
       "15                 Serde Library   \n",
       "16                   InputFormat   \n",
       "17                  OutputFormat   \n",
       "18            Storage Properties   \n",
       "19            Partition Provider   \n",
       "\n",
       "                                            data_type              comment  \n",
       "0                                                 int  Identificador único  \n",
       "1                                              string    Nome do indivíduo  \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                       spark_catalog                       \n",
       "5                                                mydb                       \n",
       "6                                         local_table                       \n",
       "7                                                root                       \n",
       "8                        Tue Aug 13 18:14:55 UTC 2024                       \n",
       "9                                             UNKNOWN                       \n",
       "10                                        Spark 3.5.1                       \n",
       "11                                            MANAGED                       \n",
       "12                                               hive                       \n",
       "13                 [transient_lastDdlTime=1723572895]                       \n",
       "14  file:/opt/apps/spark-warehouse/mydb.db/local_t...                       \n",
       "15  org.apache.hadoop.hive.serde2.lazy.LazySimpleS...                       \n",
       "16           org.apache.hadoop.mapred.TextInputFormat                       \n",
       "17  org.apache.hadoop.hive.ql.io.HiveIgnoreKeyText...                       \n",
       "18                           [serialization.format=1]                       \n",
       "19                                            Catalog                       "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    describe table extended mydb.local_table\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a28fdcc-6a1d-4158-9d20-8d672688a6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    INSERT INTO mydb.local_table VALUES (1, \"John\"), (2, \"Maria\")\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34bde18-d4e4-43e9-8f73-f0bd9894132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name| id|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "|Braga|  2|\n",
      "|Steve|  3|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuple_list_data = [('Alice', 1), ('Braga', 2), ('Steve', 3)]\n",
    "spark.createDataFrame(tuple_list_data, ['name', 'id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a198be61-2a71-44a2-b3ea-db2762f11317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name\n",
       "0   1   John\n",
       "1   2  Maria"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.table(\"mydb.local_table\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c9a81-6d78-4a21-a239-87c295c0cff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece93f6b-c6f8-4200-be8c-e24d45c52594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc638ad-56c9-4f64-9efe-17a352b460bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c10d9-867e-49a6-8e60-9651c11faee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef2e87-693a-4213-a168-8a17cd15739d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c341ba-932e-4cc7-9cba-327084ca4bde",
   "metadata": {},
   "source": [
    "## Derby Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b77ac5-faaf-4038-afbb-c622e65269fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-13 18:05:11,380 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Deleted /hive-warehouse\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /hive-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c001a-a5ba-48c4-ad05-48db5a1d9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# this one uses spark default metastore based on derby\n",
    "\n",
    "warehouse_path = \"/hive-warehouse\"  # path to warehouse in HDFS hdfs://localhost:9000/hive-warehouse\n",
    "\n",
    "# Inicializar a SparkSession com suporte ao Hive\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Derby Metastore\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-hive_2.12:3.5.1\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_path) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef85ebaf-d593-4997-9e43-c4e574b3a0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark_catalog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         catalog\n",
       "0  spark_catalog"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW catalogs\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940c6ad2-c143-412b-9300-58e5c717c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS mydb\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9909a34b-630c-4658-aa9e-7605d2bc572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mydb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace\n",
       "0   default\n",
       "1      mydb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW databases\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb789de-8b8c-4369-b1c2-05ff13c0f760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE mydb.hive_table (\n",
    "    id INT COMMENT 'Identificador único',\n",
    "    name STRING COMMENT 'Nome do indivíduo'\n",
    ") USING hive\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610c0209-5891-4ba4-8aba-2b17d26ddf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [namespace, tableName, isTemporary]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW tables\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e8db12-2ad4-44c5-8f8e-af3c351120bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int</td>\n",
       "      <td>Identificador único</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>string</td>\n",
       "      <td>Nome do indivíduo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catalog</td>\n",
       "      <td>spark_catalog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Database</td>\n",
       "      <td>mydb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Table</td>\n",
       "      <td>hive_table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Owner</td>\n",
       "      <td>root</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Created Time</td>\n",
       "      <td>Tue Aug 13 18:09:16 UTC 2024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Last Access</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Created By</td>\n",
       "      <td>Spark 3.5.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Provider</td>\n",
       "      <td>hive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[transient_lastDdlTime=1723572556]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Location</td>\n",
       "      <td>hdfs://localhost:9000/hive-warehouse/mydb.db/h...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Serde Library</td>\n",
       "      <td>org.apache.hadoop.hive.serde2.lazy.LazySimpleS...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InputFormat</td>\n",
       "      <td>org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OutputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyText...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Storage Properties</td>\n",
       "      <td>[serialization.format=1]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Partition Provider</td>\n",
       "      <td>Catalog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  \\\n",
       "0                             id   \n",
       "1                           name   \n",
       "2                                  \n",
       "3   # Detailed Table Information   \n",
       "4                        Catalog   \n",
       "5                       Database   \n",
       "6                          Table   \n",
       "7                          Owner   \n",
       "8                   Created Time   \n",
       "9                    Last Access   \n",
       "10                    Created By   \n",
       "11                          Type   \n",
       "12                      Provider   \n",
       "13              Table Properties   \n",
       "14                      Location   \n",
       "15                 Serde Library   \n",
       "16                   InputFormat   \n",
       "17                  OutputFormat   \n",
       "18            Storage Properties   \n",
       "19            Partition Provider   \n",
       "\n",
       "                                            data_type              comment  \n",
       "0                                                 int  Identificador único  \n",
       "1                                              string    Nome do indivíduo  \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                       spark_catalog                       \n",
       "5                                                mydb                       \n",
       "6                                          hive_table                       \n",
       "7                                                root                       \n",
       "8                        Tue Aug 13 18:09:16 UTC 2024                       \n",
       "9                                             UNKNOWN                       \n",
       "10                                        Spark 3.5.1                       \n",
       "11                                            MANAGED                       \n",
       "12                                               hive                       \n",
       "13                 [transient_lastDdlTime=1723572556]                       \n",
       "14  hdfs://localhost:9000/hive-warehouse/mydb.db/h...                       \n",
       "15  org.apache.hadoop.hive.serde2.lazy.LazySimpleS...                       \n",
       "16           org.apache.hadoop.mapred.TextInputFormat                       \n",
       "17  org.apache.hadoop.hive.ql.io.HiveIgnoreKeyText...                       \n",
       "18                           [serialization.format=1]                       \n",
       "19                                            Catalog                       "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    describe table extended mydb.hive_table\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93d98b7-3c83-428b-9a04-7c5b08b684b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    INSERT INTO mydb.hive_table VALUES (1, \"John\"), (2, \"Maria\")\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53a59de6-f74c-40e9-bb3b-4021b634d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name\n",
       "0   1   John\n",
       "1   2  Maria"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.table(\"mydb.hive_table\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656ed65-0b38-4257-89c5-d7ed7627fd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f186cd-0e3b-4c84-be8c-ebd6764d581b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5fc4f-3a35-40b7-a769-879949ea3c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a08f3c-1b26-409d-9c41-ec0c3399543c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346d0fa-0259-4ab2-ad20-2cd8790665a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca7e698-03c8-46e8-af98-862341216e5f",
   "metadata": {},
   "source": [
    "## Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b92df6-cc91-4a69-84fa-daf1b29f5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-04 20:55:15,492 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Deleted /delta-warehouse\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /delta-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3bcab-854d-4589-a7ac-102a5158bdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warehouse_path = \"/delta-warehouse\"  # path to warehouse in HDFS hdfs://localhost:9000/delta-warehouse\n",
    "enable_schema_merge = \"true\"\n",
    "type_compatibility_policy = \"LEGACY\"  # legacy enables more flexibility\n",
    "\n",
    "# Inicializar a SparkSession com suporte ao Delta Lake\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"delta lake\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_path) \\\n",
    "    .config(\"spark.databricks.delta.schema.autoMerge.enabled\", enable_schema_merge) \\\n",
    "    .config(\"spark.sql.storeAssignmentPolicy\", type_compatibility_policy) \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1eb35aa-e050-4fbb-b676-9bb7b6d42664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark_catalog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         catalog\n",
       "0  spark_catalog"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW catalogs\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7118d7c-d034-40c6-b50f-ac72b758f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark_catalog'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentCatalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5e6126-cec7-4461-9eba-fcf35bc30b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS mydb\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2236b2a-92fb-485e-85ff-5ea08be4a89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS another_db\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bce2e7a-4cc9-4e73-adf6-a52585ae758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mydb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    namespace\n",
       "0  another_db\n",
       "1     default\n",
       "2        mydb"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW databases\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a52767-783c-46c9-a608-f9dc383c6c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma tabela Delta Lake\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE mydb.delta_table (\n",
    "    id INT COMMENT 'Identificador único',\n",
    "    name STRING COMMENT 'Nome do indivíduo'\n",
    ") USING delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "061aca00-f2f2-4150-ab5e-2928c19f61d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>partitionColumns</th>\n",
       "      <th>clusteringColumns</th>\n",
       "      <th>numFiles</th>\n",
       "      <th>sizeInBytes</th>\n",
       "      <th>properties</th>\n",
       "      <th>minReaderVersion</th>\n",
       "      <th>minWriterVersion</th>\n",
       "      <th>tableFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>812b9bda-93d7-4344-ab48-7b85ceaa5ccf</td>\n",
       "      <td>spark_catalog.mydb.delta_table_2</td>\n",
       "      <td>None</td>\n",
       "      <td>hdfs://localhost:9000/delta-warehouse/mydb.db/...</td>\n",
       "      <td>2024-08-04 20:58:39.577</td>\n",
       "      <td>2024-08-04 20:58:40.850</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[appendOnly, invariants]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  format                                    id  \\\n",
       "0  delta  812b9bda-93d7-4344-ab48-7b85ceaa5ccf   \n",
       "\n",
       "                               name description  \\\n",
       "0  spark_catalog.mydb.delta_table_2        None   \n",
       "\n",
       "                                            location               createdAt  \\\n",
       "0  hdfs://localhost:9000/delta-warehouse/mydb.db/... 2024-08-04 20:58:39.577   \n",
       "\n",
       "             lastModified partitionColumns clusteringColumns  numFiles  \\\n",
       "0 2024-08-04 20:58:40.850               []                []         0   \n",
       "\n",
       "   sizeInBytes properties  minReaderVersion  minWriterVersion  \\\n",
       "0            0         {}                 1                 2   \n",
       "\n",
       "              tableFeatures  \n",
       "0  [appendOnly, invariants]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Criar outra tabela delta\n",
    "DeltaTable.createOrReplace(spark) \\\n",
    "    .tableName(\"mydb.delta_table_2\") \\\n",
    "    .addColumn(\"id\", dataType=\"INT\", nullable=False, comment= \"Identificador único\") \\\n",
    "    .addColumn(\"name\", dataType=StringType(), comment=\"Identificador único\") \\\n",
    "    .execute() \\\n",
    "    .detail() \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf11db9-7434-4072-bd3b-0544fab93959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mydb</td>\n",
       "      <td>delta_table</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mydb</td>\n",
       "      <td>delta_table_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace      tableName  isTemporary\n",
       "0      mydb    delta_table        False\n",
       "1      mydb  delta_table_2        False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW tables in mydb\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c50327cf-99b9-44ae-bc86-7542f1b742a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int</td>\n",
       "      <td>Identificador único</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>string</td>\n",
       "      <td>Nome do indivíduo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name</td>\n",
       "      <td>spark_catalog.mydb.delta_table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Type</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Location</td>\n",
       "      <td>hdfs://localhost:9000/delta-warehouse/mydb.db/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Provider</td>\n",
       "      <td>delta</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[delta.minReaderVersion=1,delta.minWriterVersi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col_name  \\\n",
       "0                            id   \n",
       "1                          name   \n",
       "2                                 \n",
       "3  # Detailed Table Information   \n",
       "4                          Name   \n",
       "5                          Type   \n",
       "6                      Location   \n",
       "7                      Provider   \n",
       "8              Table Properties   \n",
       "\n",
       "                                           data_type              comment  \n",
       "0                                                int  Identificador único  \n",
       "1                                             string    Nome do indivíduo  \n",
       "2                                                                          \n",
       "3                                                                          \n",
       "4                     spark_catalog.mydb.delta_table                       \n",
       "5                                            MANAGED                       \n",
       "6  hdfs://localhost:9000/delta-warehouse/mydb.db/...                       \n",
       "7                                              delta                       \n",
       "8  [delta.minReaderVersion=1,delta.minWriterVersi...                       "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    describe table extended mydb.delta_table\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bfd5426-6780-40d8-afaf-9d8739f1bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    INSERT INTO mydb.delta_table VALUES (1, \"John\"), (2, \"Maria\")\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd931de3-6766-461e-abbf-8219287a0d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True)\n",
    "])\n",
    "\n",
    "tuple_list_data = [(1, 'Alice'), (2, 'John'), (3, 'Steve')]\n",
    "df = spark.createDataFrame(tuple_list_data, schema=schema)\n",
    "\n",
    "df.write \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"mydb.delta_table\", format=\"delta\", mode=\"overwrite\")\n",
    "\n",
    "# df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"mydb.delta_table\")\n",
    "\n",
    "# df.write \\\n",
    "#   .format(\"delta\") \\\n",
    "#   .mode(\"overwrite\") \\\n",
    "#   .saveAsTable(\"mydb.delta_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4ffc154-2d3a-465a-bd1c-1d042c38e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name\n",
       "0   1  Alice\n",
       "1   2   John\n",
       "2   3  Steve"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.table(\"mydb.delta_table\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1298a-8cc1-4e1b-a548-44e15d6f7c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f8bc6-3379-48a0-aed8-8ce82611624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb45d388-9bf5-47fe-b06d-e3c81af4f497",
   "metadata": {},
   "source": [
    "## Iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686cf81-01d5-483b-ac4b-ea8f7b7d67c9",
   "metadata": {},
   "source": [
    "A catalog is created and named by adding a property spark.sql.catalog.(catalog-name) with an implementation class for its value.\n",
    "\n",
    "Iceberg supplies two implementations:\n",
    "\n",
    "- **org.apache.iceberg.spark.SparkCatalog** supports a Hive Metastore or a Hadoop warehouse as a catalog\n",
    "- **org.apache.iceberg.spark.SparkSessionCatalog** adds support for Iceberg tables to Spark's built-in catalog, and delegates to the built-in catalog for non-Iceberg table\n",
    "\n",
    "Reference: https://iceberg.apache.org/docs/latest/spark-configuration/#catalog-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90c8fbb-7030-4d60-a1bc-3fa85234cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-04 13:46:17,773 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Deleted /iceberg-warehouse\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /iceberg-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76bf4d1-5b94-489a-a44a-8e50e31cd60c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-without-hadoop/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c68c5838-ae14-4ee0-8a5a-54c0a6d402c5;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.0 in central\n",
      ":: resolution report :: resolve 52ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c68c5838-ae14-4ee0-8a5a-54c0a6d402c5\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/4ms)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>iceberg</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff88aee4f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# catalog_type = \"hive\"  # tables from a Hive metastore\n",
    "catalog_type = \"hadoop\"  # directory-based catalog in HDFS\n",
    "warehouse_path = \"/iceberg-warehouse\"  # path to warehouse in HDFS hdfs://localhost:9000/iceberg-warehouse\n",
    "\n",
    "# Inicializar a SparkSession com suporte ao Iceberg\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"iceberg\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg_catalog.type\", catalog_type) \\\n",
    "    .config(\"spark.sql.catalog.iceberg_catalog.warehouse\", warehouse_path) \\\n",
    "    .config(\"spark.sql.defaultCatalog\", \"iceberg_catalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark\n",
    "\n",
    "# another approach\n",
    "# .config(\"spark.sql.catalog.iceberg_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "# .config(\"spark.sql.catalog.iceberg_catalog.type\", \"hive\")\n",
    "\n",
    "# remote catalog\n",
    "# .config(\"spark.sql.catalog.iceberg_catalog.uri\", \"thrift://localhost:9083\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f915e376-b15f-4fa7-b12d-a6a1296a667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.setCurrentCatalog(\"iceberg_catalog\")\n",
    "\n",
    "# OR by setting up\n",
    "\n",
    "# .config(\"spark.sql.defaultCatalog\", \"iceberg_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff133bd-6025-42f8-b07b-5fa0f6145f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iceberg_catalog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spark_catalog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           catalog\n",
       "0  iceberg_catalog\n",
       "1    spark_catalog"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW catalogs\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8b6ec2-aa4f-4c2e-b937-c807c2fd942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iceberg_catalog'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentCatalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3423c022-dc93-4f35-9b96-1b9bc6de968f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS iceberg_catalog.mydb\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3fd0de-fd04-4c2a-a220-feb4e6073e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mydb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace\n",
       "0      mydb"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW databases\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7f1e6f-c222-4dd2-a01e-6763bf459575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma tabela Iceberg\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE mydb.iceberg_table (\n",
    "    id INT COMMENT 'Identificador único',\n",
    "    name STRING COMMENT 'Nome do indivíduo'\n",
    ") USING iceberg\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8baf8c6-c1af-4654-9fcd-a3e0405a22b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mydb</td>\n",
       "      <td>iceberg_table</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace      tableName  isTemporary\n",
       "0      mydb  iceberg_table        False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW tables in mydb\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87cff1dd-0d97-4795-b596-34308d446757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int</td>\n",
       "      <td>Identificador único</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>string</td>\n",
       "      <td>Nome do indivíduo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Metadata Columns</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_spec_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_partition</td>\n",
       "      <td>struct&lt;&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_file</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_pos</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_deleted</td>\n",
       "      <td>boolean</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Name</td>\n",
       "      <td>iceberg_catalog.mydb.iceberg_table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Type</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Location</td>\n",
       "      <td>/iceberg-warehouse/mydb/iceberg_table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Provider</td>\n",
       "      <td>iceberg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Owner</td>\n",
       "      <td>root</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[current-snapshot-id=none,format=iceberg/parqu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  \\\n",
       "0                             id   \n",
       "1                           name   \n",
       "2                                  \n",
       "3             # Metadata Columns   \n",
       "4                       _spec_id   \n",
       "5                     _partition   \n",
       "6                          _file   \n",
       "7                           _pos   \n",
       "8                       _deleted   \n",
       "9                                  \n",
       "10  # Detailed Table Information   \n",
       "11                          Name   \n",
       "12                          Type   \n",
       "13                      Location   \n",
       "14                      Provider   \n",
       "15                         Owner   \n",
       "16              Table Properties   \n",
       "\n",
       "                                            data_type              comment  \n",
       "0                                                 int  Identificador único  \n",
       "1                                              string    Nome do indivíduo  \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                 int                       \n",
       "5                                            struct<>                       \n",
       "6                                              string                       \n",
       "7                                              bigint                       \n",
       "8                                             boolean                       \n",
       "9                                                                           \n",
       "10                                                                          \n",
       "11                 iceberg_catalog.mydb.iceberg_table                       \n",
       "12                                            MANAGED                       \n",
       "13              /iceberg-warehouse/mydb/iceberg_table                       \n",
       "14                                            iceberg                       \n",
       "15                                               root                       \n",
       "16  [current-snapshot-id=none,format=iceberg/parqu...                       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    describe table extended mydb.iceberg_table\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e796019-6ea0-4893-8f29-dd30390e2a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    INSERT INTO mydb.iceberg_table VALUES (1, \"John\"), (2, \"Maria\")\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e087ea1-83bf-45ae-9673-61afd06af89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name\n",
       "0   1   John\n",
       "1   2  Maria"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.table(\"mydb.iceberg_table\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a02b3-6ed8-4720-a3ad-63f373ae2d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76757ded-45a2-4520-8051-4cf7df268519",
   "metadata": {},
   "source": [
    "## Glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da8740-400e-4659-95de-bc1adf375e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ACCESS_KEY = \"\"\n",
    "SECRET_KEY = \"\"\n",
    "# Inicializar a SparkSession com suporte ao Glue Catalog\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Glue Catalog Example\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.4.0\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", ACCESS_KEY) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", SECRET_KEY) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.sql.catalog.glue_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"hive.metastore.client.factory.class\", \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "    .config(\"spark.hadoop.hive.metastore.glue.catalogid\", \"667047950229\") \\\n",
    "     .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbbe6b-a1cd-4137-84b2-3526d6807f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91143816-7d0a-4ba3-88c7-14811676c7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
