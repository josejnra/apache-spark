version: '3.7'

networks: 
  spark:

services: 

  spark:
    image: spark-yarn:3.1.2
    container_name: spark
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 8080:8080 # Spark UI
      - 7077:7077
      - 4040:4040
      - 8088:8088 # Resource Manager UI
      - 9864:9864 # Datanode port
      - 9870:9870 # HDFS UI
    volumes: 
      - ./apps:/opt/apps
      - ./conf/core-site.xml:/home/hadoop/hadoop-3.3.1/etc/hadoop/core-site.xml
      - ./conf/hdfs-site.xml:/home/hadoop/hadoop-3.3.1/etc/hadoop/hdfs-site.xml
      - ./conf/mapred-site.xml:/home/hadoop/hadoop-3.3.1/etc/hadoop/mapred-site.xml
      - ./conf/yarn-site.xml:/home/hadoop/hadoop-3.3.1/etc/hadoop/yarn-site.xml
    command:
      - "-c"
      - |
        echo "Starting ssh service..."
        service ssh start

        # ssh-keyscan -H localhost >> ~/.ssh/known_hosts

        echo "Formating the filesystem..."
        hdfs namenode -format
        
        echo "Starting NameNode, DataNode, Resource Manager and Node Manager..."
        hdfs --daemon start namenode
        hdfs --daemon start datanode
        yarn --daemon start resourcemanager
        yarn --daemon start nodemanager
        yarn --daemon start proxyserver
        mapred --daemon start historyserver

        echo "Creating the HDFS directories required to execute MapReduce jobs..."
        hdfs dfs -mkdir /user
        hdfs dfs -mkdir /user/$$(whoami)

        echo "Starting spark"
        /opt/spark-3.1.2-bin-without-hadoop/sbin/start-all.sh
        /opt/spark-3.1.2-bin-without-hadoop/sbin/start-history-server.sh

        tail -f /home/hadoop/hadoop-3.3.1/logs/*log
